\section{Discussion}
\label{sec:discussion}

We have shown that multitask basis pursuit can help select isometric submatrices from appropriately normalized wide matrices.
This approach - isometry pursuit - is a convex alternative to greedy methods for selection of orthonormalized features from within a dictionary.
Isometry pursuit can be applied to diversification and geometrically-faithful coordinate estimation.
Our experiments exemplify these applications, but more can be done.

One potential application is diversification in recommendation systems \citep{Carbonell2017-gi, Wu2019-uk, Langchain} and other retrieval systems such as in RAG \citep{Gao2023-cn, Pickett2024-ad, In2024-um, Weiss2024-xm, Vectara}.
This is particularly relevant as maximum cosine similarity used in retrieval corresponds to the first coefficient of the Lasso regularization path \citep{Koelle2022-ju}.
Compared with the greedy algorithms used in diversification \citep{Carbonell1998-ji, Barioni, Drosou, Qin2012-ok, KUNAVER2017154, Guo-shengbo, Abdool,Yu2016AGA,  Huang2024-wr, Pickett2024-ad, 5895106, Zhu2020-vb}, the convex reformulation may add speed and convergence to a global minima.
However, we note that the standard max-sum diversity formulation that seeks to identify datapoints that are as far apart as possible is substantially different from the notion of diversity selected for by Isometry Pursuit \citep{Kuo1993-zy, Ghosh1996-id, Alfonso-Cevallos-Friedrich-Eisenbrand-and-Rico-Zenklusen2016-ai, Ashkan2015-jv}.

The comparison of greedy \cite{Mallat93-wi, Mallat, Pati-93, Tropp05-ml} and convex \citep{Chen2001-hh, Tropp06-sg,Chen2006TheoreticalRO} basis pursuit formulations has a rich history, and theoretical understanding of the behavior of this approximation is evolving.
For example, that the solution of a lasso problem can sometimes be a non-singleton set is well-known \citep{Osborne2000OnTL, DOSSAL2012117, Chrtien2011OnTG, Tibshirani2012TheLP, Ewald2017OnTD, Ali2018TheGL, Schneider2020-qt, Mishkin2022TheSP,Dupuis2019TheGO,Debarre2020OnTU,Everink2024TheGA}, but Isometry Pursuit can generate non-unique solutions even when the design matrix satisfies general position.
The nature of the approximation to the $\ell_0$ solution for Isometry Pursuit is also different than for standard Lasso theory.
The main theoretical question of isometry pursuit is how well the minimizer of a convex loss approximates the singular value loss, rather than how well the convex loss performs in statistical estimation.

Algorithmic variants include the multitask lasso \citep{ Hastie2015-qa} extension of our estimator, as well as characterization of $D$ function selection within $\mathbb R^B$.
Tangent-space specific variants have been studied in more detail in \citet{Koelle2022-ju, Koelle2024-no} with additional grouping across datapoints, and a corresponding variant of the isometry theorem that missed non-uniqueness was claimed in \citet{Koelle2022-lp}.
Comparison of our loss with curvature - whose presence prohibits $D$ element isometry - could also prove fertile, as could the convex matrix inversion of multitask basis pursuit.